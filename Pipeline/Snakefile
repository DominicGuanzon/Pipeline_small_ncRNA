"""

Pipeline to process small non-coding RNA species from small RNA NGS using NextFlex library preperation.

"""

import pandas as pd
import sys

# Read Sample_file.tsv
sample_sheet = pd.read_table("../Config/Sample_file.tsv")

# Check for duplicate sample names, terminate if true
if sample_sheet["Sample_name"].duplicated().any() == True:
    sys.exit("You have duplicate sample names in Sample_file.tsv")

# Check for empty sample_names
if sample_sheet["Sample_name"].isnull().any() == True:
    sys.exit("You have empty sample names in Sample_file.tsv")

# Add sample names to index
sample_sheet = sample_sheet.set_index("Sample_name", drop=False)

genome_names = list(sample_sheet["Genome"])
sample_names = list(sample_sheet["Sample_name"])
genome_list = list(set(sample_sheet["Genome"]))

# Create bowtie and miRBase names
bowtie_names = []
miRBase_names = []

for genome_var in genome_list:
    if genome_var == "human":
        bowtie_names.append("GCA_000001405.15_GRCh38_no_alt_analysis_set")
        miRBase_names.append("hsa")
    elif genome_var == "pig":
        bowtie_names.append("genome")
        miRBase_names.append("ssc")
    elif genome_var == "chinese_hamster":
        bowtie_names.append("chok1gshd")
        miRBase_names.append("cgr")
        

# Rule to specify final output files
rule all:
    input:
        miRDeep2_plots = expand("Final_outputs/{genome_folder}/miRDeep2_summary_plots.pdf", genome_folder = genome_list),
        unitas_plots = expand("Final_outputs/{genome_folder}/Unitas_summary_plots.pdf", genome_folder = genome_list),
        read_loss_plots = expand("Final_outputs/{genome_folder}/Read_loss_plots.pdf", genome_folder = genome_list)


# Download or install Bowtie databases required for pipeline.
rule bowtie_databases:
    output:
        "Required_files/{genome_folder}/{bowtie_name}.1.ebwt",
        "Required_files/{genome_folder}/{bowtie_name}.2.ebwt",
        "Required_files/{genome_folder}/{bowtie_name}.3.ebwt",
        "Required_files/{genome_folder}/{bowtie_name}.4.ebwt",
        "Required_files/{genome_folder}/{bowtie_name}.rev.1.ebwt",
        "Required_files/{genome_folder}/{bowtie_name}.rev.2.ebwt"
    script:
        "Scripts/Bowtie_databases.py"


# Download miRBase databases
rule miRBase_download:
    output:
        mature_miR = "Required_files/miRBase/mature.fa",
        hairpin_miR = "Required_files/miRBase/hairpin.fa"
    script:
        "Scripts/miRBase_download.py"


# Install miRBase databases required for pipeline.
rule miRBase_databases:
    input:
        "Required_files/miRBase/mature.fa",
        "Required_files/miRBase/hairpin.fa"
    output:
        "Required_files/miRBase/{miRBase_name}_mature.fa",
        "Required_files/miRBase/{miRBase_name}_hairpin.fa"
    script:
        "Scripts/miRBase_databases.py"


# Remove adaptors using cutadapt
rule remove_adaptors:
    input:
        bowtie_db = expand(["Required_files/{genome_folder}/{bowtie_name}.1.ebwt", "Required_files/{genome_folder}/{bowtie_name}.2.ebwt",
                        "Required_files/{genome_folder}/{bowtie_name}.3.ebwt", "Required_files/{genome_folder}/{bowtie_name}.4.ebwt",
                        "Required_files/{genome_folder}/{bowtie_name}.rev.1.ebwt", "Required_files/{genome_folder}/{bowtie_name}.rev.2.ebwt"],
                        zip, genome_folder = genome_list, bowtie_name = bowtie_names),
        miRBase_db = expand(["Required_files/miRBase/{miRBase_name}_mature.fa", "Required_files/miRBase/{miRBase_name}_hairpin.fa"], miRBase_name = miRBase_names),
        input_fastq = lambda wildcards: "Data/" + sample_sheet.loc[wildcards.sample, "File_name"]
    output:
        "Adaptor_removed/{sample}_cleaned.fastq"
    log:
        out = "Adaptor_removed/Log/{sample}.stdout",
        err = "Adaptor_removed/Log/{sample}.stderr"
    params:
        library_type = lambda wildcards: sample_sheet.loc[wildcards.sample, "Library_type"]
    run:
        if params.library_type == "truseq":
            shell("cutadapt -a TGGAATTCTCGGGTGCCAAGG -o {output} --minimum-length 14 {input.input_fastq} > {log.out} 2> {log.err}")
        if params.library_type == "nextflex":
            shell("cutadapt -a TGGAATTCTCGGGTGCCAAGG -o {output} --minimum-length 22 {input.input_fastq} > {log.out} 2> {log.err}")


# Trim reads based on library preperation kit.
rule trim_read:
    input:
        "Adaptor_removed/{sample}_cleaned.fastq"
    output:
        "Trimmed_reads/{genome_type}/{sample}_trimmed.fastq"
    log:
        out = "Trimmed_reads/{genome_type}/Log/{sample}.stdout",
        err = "Trimmed_reads/{genome_type}/Log/{sample}.stderr"
    params:
        library_type = lambda wildcards: sample_sheet.loc[wildcards.sample, "Library_type"]
    run:
        if params.library_type == "truseq":
            shell("cp {input} {output} > {log.out} 2> {log.err}")
        if params.library_type == "nextflex":
            shell("cutadapt -u 4 -u -4 -o {output} {input} > {log.out} 2> {log.err}")


# Annotate reads using unitas.
rule annotate_read:
    input:
        expand("Trimmed_reads/{genome_type}/{sample}_trimmed.fastq", zip, genome_type = genome_names, sample = sample_names)
    output:
        "Unitas_annotated_reads/{genome_folder}/Log/Done.txt"
    log:
        out = "Unitas_annotated_reads/{genome_folder}/Log/Unitas.stdout",
        err = "Unitas_annotated_reads/{genome_folder}/Log/Unitas.stderr"
    threads: 1
    run:
        if wildcards.genome_folder == "human":
            shell("cd Unitas_annotated_reads/{wildcards.genome_folder} && unitas_1.7.0.pl -input ../../Trimmed_reads/{wildcards.genome_folder} -species homo_sapiens -threads {threads} > ../../{log.out} 2> ../../{log.err} && touch ../../{output}")
        if wildcards.genome_folder == "chinese_hamster":
            shell("cd Unitas_annotated_reads/{wildcards.genome_folder} && unitas_1.7.0.pl -input ../../Trimmed_reads/{wildcards.genome_folder} -species cricetulus_griseus_chok1gshd -threads {threads} > ../../{log.out} 2> ../../{log.err} && touch ../../{output}")
        if wildcards.genome_folder == "pig":
            shell("cd Unitas_annotated_reads/{wildcards.genome_folder} && unitas_1.7.0.pl -input ../../Trimmed_reads/{wildcards.genome_folder} -species sus_scrofa -threads {threads} > ../../{log.out} 2> ../../{log.err} && touch ../../{output}")      


# Map trimmed reads to genome using miRDeep2
rule miRDeep2_map:
    input:
        "Trimmed_reads/{genome_type}/{sample}_trimmed.fastq"
    output:
        collapsed_fa = "miRDeep2_output/{genome_type}/{sample}_miRDeep2_collapsed.fa",
        alligned_arf = "miRDeep2_output/{genome_type}/{sample}_miRDeep2_alligned.arf"
    log:
        out = "miRDeep2_output/{genome_type}/Log_mapped/{sample}.stdout",
        err = "miRDeep2_output/{genome_type}/Log_mapped/{sample}.stderr"
    run:
        if wildcards.genome_type == "human":
            shell("cd miRDeep2_output/{wildcards.genome_type} && mapper.pl ../../{input} -e -h -l 16 -m -p '../../Required_files/{wildcards.genome_type}/GCA_000001405.15_GRCh38_no_alt_analysis_set' -q -s ../../{output.collapsed_fa} -t ../../{output.alligned_arf} > ../../{log.out} 2> ../../{log.err}")
        if wildcards.genome_type == "chinese_hamster":
            shell("cd miRDeep2_output/{wildcards.genome_type} && mapper.pl ../../{input} -e -h -l 16 -m -p '../../Required_files/{wildcards.genome_type}/chok1gshd' -q -s ../../{output.collapsed_fa} -t ../../{output.alligned_arf} > ../../{log.out} 2> ../../{log.err}")
        if wildcards.genome_type == "pig":
            shell("cd miRDeep2_output/{wildcards.genome_type} && mapper.pl ../../{input} -e -h -l 16 -m -p '../../Required_files/{wildcards.genome_type}/genome' -q -s ../../{output.collapsed_fa} -t ../../{output.alligned_arf} > ../../{log.out} 2> ../../{log.err}")


# Quantify reads mapped by miRDeep2 
rule miRDeep2_quantify:
    input:
        collapsed_fa = "miRDeep2_output/{genome_type}/{sample}_miRDeep2_collapsed.fa",
        alligned_arf = "miRDeep2_output/{genome_type}/{sample}_miRDeep2_alligned.arf"
    output:
        "miRDeep2_output/{genome_type}/expression_analyses/expression_analyses_{sample}/miRBase.mrd"
    log:
        out = "miRDeep2_output/{genome_type}/Log_quantified/{sample}.stdout",
        err = "miRDeep2_output/{genome_type}/Log_quantified/{sample}.stderr"
    run:
        if wildcards.genome_type == "human":
            shell("cd miRDeep2_output/{wildcards.genome_type} && quantifier.pl -m '../../Required_files/miRBase/hsa_mature.fa' -p '../../Required_files/miRBase/hsa_hairpin.fa' -d -y {wildcards.sample} -r ../../{input.collapsed_fa} > ../../{log.out} 2> ../../{log.err}")
        if wildcards.genome_type == "chinese_hamster":
            shell("cd miRDeep2_output/{wildcards.genome_type} && quantifier.pl -m '../../Required_files/miRBase/cgr_mature.fa' -p '../../Required_files/miRBase/cgr_hairpin.fa' -d -y {wildcards.sample} -r ../../{input.collapsed_fa} > ../../{log.out} 2> ../../{log.err}")
        if wildcards.genome_type == "pig":
            shell("cd miRDeep2_output/{wildcards.genome_type} && quantifier.pl -m '../../Required_files/miRBase/ssc_mature.fa' -p '../../Required_files/miRBase/ssc_hairpin.fa' -d -y {wildcards.sample} -r ../../{input.collapsed_fa} > ../../{log.out} 2> ../../{log.err}")

        
# Combine miRDeep2 output
rule combine_miRDeep2_output:
    input:
        expand("miRDeep2_output/{genome_type}/expression_analyses/expression_analyses_{sample}/miRBase.mrd", zip, genome_type = genome_names, sample = sample_names)
    output:
        "Final_outputs/{genome_folder}/raw_miRNA_counts_merged_miRDeep2.csv"
    params:
        input_dir = "miRDeep2_output/{genome_folder}/"
    script:
        "Scripts/Parse_miRDeep2.py"

        
# Combine Unitas output
rule combine_unitas_output:
    input:
        "Unitas_annotated_reads/{genome_folder}/Log/Done.txt"
    output:
        "Final_outputs/{genome_folder}/Unitas_annotation_summary_combined.csv",
        "Final_outputs/{genome_folder}/Unitas_hits_per_target_combined.csv",
        "Final_outputs/{genome_folder}/Unitas_tRF_table_simplified_combined.csv",
        "Final_outputs/{genome_folder}/Unitas_tRF_table_absolute_combined.csv",
        "Final_outputs/{genome_folder}/Unitas_tRF_table_fractionated_combined.csv"
    params:
        input_dir = "Unitas_annotated_reads/{genome_folder}/"
    script:
        "Scripts/Parse_unitas.py"

        
# Plot summary graphs for unitas
rule unitas_summary_graphs:
    input:
        "Final_outputs/{genome_folder}/Unitas_annotation_summary_combined.csv"
    output:
        "Final_outputs/{genome_folder}/Unitas_summary_plots.pdf"
    script:
        "Scripts/Unitas_output_graph.R"

        
# Plot summary graphs for miRDeep2
rule miRDeep2_summary_graphs:
    input:
        "Final_outputs/{genome_folder}/raw_miRNA_counts_merged_miRDeep2.csv"
    output:
        "Final_outputs/{genome_folder}/miRDeep2_summary_plots.pdf"
    script:
        "Scripts/miRDeep2_output_graph.R"

        
# Plot summary graphs for miRDeep2
rule read_loss_summary_graphs:
    input:
        adaptor_data = expand("Adaptor_removed/{sample}_cleaned.fastq", sample = sample_names),
        trimmed_data = expand("Trimmed_reads/{genome_type}/{sample}_trimmed.fastq", zip, genome_type = genome_names, sample = sample_names)
    output:
        summary_data = "Final_outputs/{genome_folder}/Read_loss.csv",
        summary_plots = "Final_outputs/{genome_folder}/Read_loss_plots.pdf"
    params:
        raw_data_folder = "Data/",
        genome_folder_var = "{genome_folder}"
    script:
        "Scripts/Parse_and_plot_read_loss.R"
